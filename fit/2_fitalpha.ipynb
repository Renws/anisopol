{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c652044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import lstsq\n",
    "\n",
    "AMINO_ACID_ATOM_COUNTS = {\n",
    "    \"ALA\": 12, \"ARG\": 26, \"ASN\": 16, \"ASP\": 14, \"CYS\": 13, \"GLN\": 19, \"GLU\": 17,\n",
    "    \"GLY\": 9, \"HID\": 19, \"ILE\": 21, \"LEU\": 21, \"LYS\": 24, \"MET\": 19, \"PHE\": 22,\n",
    "    \"PRO\": 16, \"SER\": 13, \"THR\": 16, \"TRP\": 26, \"TYR\": 23, \"VAL\": 18, \"ACE\": 7, \"NME\": 7,\n",
    "}\n",
    "\n",
    "def _read_feature_from_ef(ef_file: str, n_atoms: int, aggregate: bool = True):\n",
    "    \"\"\"\n",
    "    从单个 .ef 文件中读取特征。\n",
    "    如果 aggregate=True，返回 5 维聚合特征（对 n_atoms 求和）：\n",
    "      [sum(E_paral^2), sum(E_verti^2), sum(E_paral*E_verti), sum(|E_paral|), sum(|E_verti|)]\n",
    "    如果 aggregate=False，返回按原子拼接的 5*n_atoms 维特征（与原实现相同）。\n",
    "    \"\"\"\n",
    "    ef_data = np.loadtxt(ef_file, skiprows=1)\n",
    "    ef_data = np.atleast_2d(ef_data)\n",
    "\n",
    "    if ef_data.shape[0] < n_atoms:\n",
    "        raise ValueError(f\"EF文件行数不足: 需要 {n_atoms}, 实际 {ef_data.shape[0]} -> {ef_file}\")\n",
    "\n",
    "    # 列索引: 11 -> |E_parallel|, 12 -> |E_vertical|\n",
    "    E_paral = ef_data[:n_atoms, 11]\n",
    "    E_verti = ef_data[:n_atoms, 12]\n",
    "\n",
    "    paral_sq = E_paral**2\n",
    "    verti_sq = E_verti**2\n",
    "    prod = E_paral * E_verti\n",
    "    paral_abs = np.abs(E_paral)\n",
    "    verti_abs = np.abs(E_verti)\n",
    "\n",
    "    if aggregate:\n",
    "        # 聚合为 5 个全分子特征（默认用 sum，若你更偏好均值可改为 mean）\n",
    "        return np.array([\n",
    "            paral_sq.sum(),\n",
    "            verti_sq.sum(),\n",
    "            prod.sum(),\n",
    "            paral_abs.sum(),\n",
    "            verti_abs.sum(),\n",
    "        ])\n",
    "    else:\n",
    "        # 原始逐原子拼接\n",
    "        return np.concatenate([paral_sq, verti_sq, prod, paral_abs, verti_abs])\n",
    "\n",
    "def fit_and_predict_U(work_dir: str, residue_name: str = \"ALA\", n_train: int = 1000):\n",
    "    \"\"\"\n",
    "    用 5 个聚合特征拟合 5 个极化率参数，并在同一文件中输出：\n",
    "    name, real_U, fit_U, 5个特征, 5个alpha\n",
    "    \"\"\"\n",
    "    if residue_name not in AMINO_ACID_ATOM_COUNTS:\n",
    "        raise KeyError(f\"未在 AMINO_ACID_ATOM_COUNTS 中找到残基 {residue_name} 的原子数\")\n",
    "    n_atoms = AMINO_ACID_ATOM_COUNTS[residue_name]\n",
    "\n",
    "    ef_dir = os.path.join(work_dir, residue_name, \"ef\")\n",
    "    raw_realU_file = os.path.join(work_dir, residue_name, \"raw_realU\")\n",
    "    output_alpha_file = os.path.join(work_dir, residue_name, \"fit_alpha\")\n",
    "    output_combined_file = os.path.join(work_dir, residue_name, \"raw_realU_fitU\")\n",
    "\n",
    "    # 读取 name 与真实 U\n",
    "    data = []\n",
    "    with open(raw_realU_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            data.append((parts[0].strip(), float(parts[1])))\n",
    "\n",
    "    if not data:\n",
    "        raise RuntimeError(\"未能从 raw_realU 读取到有效数据\")\n",
    "\n",
    "    print(f\"从 {residue_name} 总共读取到 {len(data)} 个样本, 其中前 {n_train} 个用于拟合\")\n",
    "\n",
    "    # ---------------- 拟合阶段（5 维特征） ----------------\n",
    "    train_data = data[:n_train]\n",
    "    A_all, U_all = [], []\n",
    "\n",
    "    for name, real_U in train_data:\n",
    "        ef_file = os.path.join(ef_dir, name + \".ef\")\n",
    "        if not os.path.isfile(ef_file):\n",
    "            print(f\"⚠️ 缺少EF文件, 跳过: {ef_file}\")\n",
    "            continue\n",
    "        try:\n",
    "            feats5 = _read_feature_from_ef(ef_file, n_atoms, aggregate=True)  # 5维\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 无法读取EF文件, 跳过: {ef_file}, 错误: {e}\")\n",
    "            continue\n",
    "\n",
    "        A_all.append(feats5)\n",
    "        U_all.append(real_U)\n",
    "\n",
    "    A_all = np.array(A_all)\n",
    "    U_all = np.array(U_all)\n",
    "\n",
    "    if A_all.shape[0] == 0:\n",
    "        raise RuntimeError(\"没有可用的训练样本, 无法进行拟合\")\n",
    "\n",
    "    print(\"开始进行最小二乘拟合...\")\n",
    "    alpha, residuals, rank, s = lstsq(A_all, U_all, rcond=None)  # alpha 为长度 5 的向量\n",
    "\n",
    "    # 保存 alpha\n",
    "    np.savetxt(\n",
    "        output_alpha_file, alpha.reshape(1, -1),\n",
    "        header=\"alpha_paral_sq alpha_verti_sq alpha_prod alpha_paral_abs alpha_verti_abs\"\n",
    "    )\n",
    "    print(f\"✅ 极化率参数已保存至: {output_alpha_file}\")\n",
    "\n",
    "    # ---------------- 预测与合并输出 ----------------\n",
    "    # 写入表头\n",
    "    header_cols = [\n",
    "        \"name\", \"real_U\", \"fit_U\",\n",
    "        \"feat_paral_sq\", \"feat_verti_sq\", \"feat_prod\", \"feat_paral_abs\", \"feat_verti_abs\",\n",
    "        \"alpha_paral_sq\", \"alpha_verti_sq\", \"alpha_prod\", \"alpha_paral_abs\", \"alpha_verti_abs\"\n",
    "    ]\n",
    "    with open(output_combined_file, \"w\") as f:\n",
    "        f.write(\"# \" + \" \".join(header_cols) + \"\\n\")\n",
    "\n",
    "        for (name, real_U) in data:\n",
    "            ef_file = os.path.join(ef_dir, name + \".ef\")\n",
    "            if not os.path.isfile(ef_file):\n",
    "                print(f\"⚠️ 缺少EF文件, 跳过: {ef_file}\")\n",
    "                continue\n",
    "            try:\n",
    "                feats5 = _read_feature_from_ef(ef_file, n_atoms, aggregate=True)  # 5维\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 无法读取EF文件, 跳过: {ef_file}, 错误: {e}\")\n",
    "                continue\n",
    "\n",
    "            U_fit = float(feats5 @ alpha)\n",
    "\n",
    "            # 逐行输出：name, real_U, fit_U, 5个特征, 5个alpha\n",
    "            f.write(\n",
    "                f\"{name} {real_U:.6f} {U_fit:.6f} \"\n",
    "                + \" \".join([f\"{v:.6f}\" for v in feats5.tolist()])\n",
    "                + \" \"\n",
    "                + \" \".join([f\"{a:.6f}\" for a in alpha.tolist()])\n",
    "                + \"\\n\"\n",
    "            )\n",
    "\n",
    "    print(f\"✅ 所有结果已写入: {output_combined_file}\")\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b6c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 ALA 总共读取到 6921 个样本, 其中前 1000 个用于拟合\n",
      "开始进行最小二乘拟合...\n",
      "✅ 极化率参数已保存至: /home/wsren/Codes/proteinff-model/dipole/alpha/alpha_mono/pdb_amber2_del4c_new/ALA/fit_alpha\n",
      "✅ 所有结果已写入: /home/wsren/Codes/proteinff-model/dipole/alpha/alpha_mono/pdb_amber2_del4c_new/ALA/raw_realU_fitU\n"
     ]
    }
   ],
   "source": [
    "work_dir = \"/mnt/xyz_folder\"\n",
    "for amino in [\"ALA\"]:\n",
    "    fit_and_predict_U(work_dir, residue_name=amino, n_train=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
