{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c652044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import lstsq\n",
    "\n",
    "AMINO_ACID_ATOM_COUNTS = {\n",
    "    \"ALA\": 12, \"ARG\": 26, \"ASN\": 16, \"ASP\": 14, \"CYS\": 13, \"GLN\": 19, \"GLU\": 17,\n",
    "    \"GLY\": 9, \"HID\": 19, \"ILE\": 21, \"LEU\": 21, \"LYS\": 24, \"MET\": 19, \"PHE\": 22,\n",
    "    \"PRO\": 16, \"SER\": 13, \"THR\": 16, \"TRP\": 26, \"TYR\": 23, \"VAL\": 18, \"ACE\": 7, \"NME\": 7,\n",
    "}\n",
    "\n",
    "def _read_feature_from_ef(ef_file: str, n_atoms: int, aggregate: bool = True):\n",
    "    \"\"\"\n",
    "    Read features from a single .ef file.\n",
    "    If aggregate=True, return 5 aggregated features (summed over n_atoms):\n",
    "      [sum(E_paral^2), sum(E_verti^2), sum(E_paral*E_verti), sum(|E_paral|), sum(|E_verti|)]\n",
    "    If aggregate=False, return 5*n_atoms features concatenated per atom (same as the original implementation).\n",
    "    \"\"\"\n",
    "    ef_data = np.loadtxt(ef_file, skiprows=1)\n",
    "    ef_data = np.atleast_2d(ef_data)\n",
    "\n",
    "    if ef_data.shape[0] < n_atoms:\n",
    "        raise ValueError(f\"Not enough lines in EF file: expected {n_atoms}, got {ef_data.shape[0]} -> {ef_file}\")\n",
    "\n",
    "    # Column indices: 11 -> |E_parallel|, 12 -> |E_vertical|\n",
    "    E_paral = ef_data[:n_atoms, 11]\n",
    "    E_verti = ef_data[:n_atoms, 12]\n",
    "\n",
    "    paral_sq = E_paral**2\n",
    "    verti_sq = E_verti**2\n",
    "    prod = E_paral * E_verti\n",
    "    paral_abs = np.abs(E_paral)\n",
    "    verti_abs = np.abs(E_verti)\n",
    "\n",
    "    if aggregate:\n",
    "        # Aggregate into 5 molecule-level features (sum by default; switch to mean if preferred)\n",
    "        return np.array([\n",
    "            paral_sq.sum(),\n",
    "            verti_sq.sum(),\n",
    "            prod.sum(),\n",
    "            paral_abs.sum(),\n",
    "            verti_abs.sum(),\n",
    "        ])\n",
    "    else:\n",
    "        # Original per-atom concatenation\n",
    "        return np.concatenate([paral_sq, verti_sq, prod, paral_abs, verti_abs])\n",
    "\n",
    "def fit_and_predict_U(work_dir: str = \"example\", residue_name: str = \"ALA\", n_train: int = 1000):\n",
    "    \"\"\"\n",
    "    Fit five polarizability parameters using 5 aggregated features and write a combined output file:\n",
    "    name, real_U, fit_U, 5 features, 5 alphas\n",
    "    \"\"\"\n",
    "    if residue_name not in AMINO_ACID_ATOM_COUNTS:\n",
    "        raise KeyError(f\"Residue {residue_name} not found in AMINO_ACID_ATOM_COUNTS\")\n",
    "    n_atoms = AMINO_ACID_ATOM_COUNTS[residue_name]\n",
    "\n",
    "    ef_dir = os.path.join(work_dir, residue_name, \"ef\")\n",
    "    raw_realU_file = os.path.join(work_dir, residue_name, \"raw_realU\")\n",
    "    output_alpha_file = os.path.join(work_dir, residue_name, \"fit_alpha\")\n",
    "    output_combined_file = os.path.join(work_dir, residue_name, \"raw_realU_fitU\")\n",
    "\n",
    "    # Read name and reference U\n",
    "    data = []\n",
    "    with open(raw_realU_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            data.append((parts[0].strip(), float(parts[1])))\n",
    "\n",
    "    if not data:\n",
    "        raise RuntimeError(\"Failed to read valid entries from raw_realU\")\n",
    "\n",
    "    print(f\"Read {len(data)} samples for {residue_name}; first {n_train} used for fitting\")\n",
    "\n",
    "    # ---------------- Fitting stage (5D features) ----------------\n",
    "    train_data = data[:n_train]\n",
    "    A_all, U_all = [], []\n",
    "\n",
    "    for name, real_U in train_data:\n",
    "        ef_file = os.path.join(ef_dir, name + \".ef\")\n",
    "        if not os.path.isfile(ef_file):\n",
    "            print(f\"⚠️ Missing EF file, skipping: {ef_file}\")\n",
    "            continue\n",
    "        try:\n",
    "            feats5 = _read_feature_from_ef(ef_file, n_atoms, aggregate=True)  # 5D\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to read EF file, skipping: {ef_file}, error: {e}\")\n",
    "            continue\n",
    "\n",
    "        A_all.append(feats5)\n",
    "        U_all.append(real_U)\n",
    "\n",
    "    A_all = np.array(A_all)\n",
    "    U_all = np.array(U_all)\n",
    "\n",
    "    if A_all.shape[0] == 0:\n",
    "        raise RuntimeError(\"No usable training samples; cannot perform fitting\")\n",
    "\n",
    "    print(\"Starting least-squares fitting...\")\n",
    "    alpha, residuals, rank, s = lstsq(A_all, U_all, rcond=None)  # alpha is a length-5 vector\n",
    "\n",
    "    # Save alpha\n",
    "    np.savetxt(\n",
    "        output_alpha_file, alpha.reshape(1, -1),\n",
    "        header=\"alpha_paral_sq alpha_verti_sq alpha_prod alpha_paral_abs alpha_verti_abs\"\n",
    "    )\n",
    "    print(f\"✅ Polarizability parameters saved to: {output_alpha_file}\")\n",
    "\n",
    "    # ---------------- Prediction and merged output ----------------\n",
    "    # Write header\n",
    "    header_cols = [\n",
    "        \"name\", \"real_U\", \"fit_U\",\n",
    "        \"feat_paral_sq\", \"feat_verti_sq\", \"feat_prod\", \"feat_paral_abs\", \"feat_verti_abs\",\n",
    "        \"alpha_paral_sq\", \"alpha_verti_sq\", \"alpha_prod\", \"alpha_paral_abs\", \"alpha_verti_abs\"\n",
    "    ]\n",
    "    with open(output_combined_file, \"w\") as f:\n",
    "        f.write(\"# \" + \" \".join(header_cols) + \"\\n\")\n",
    "\n",
    "        for (name, real_U) in data:\n",
    "            ef_file = os.path.join(ef_dir, name + \".ef\")\n",
    "            if not os.path.isfile(ef_file):\n",
    "                print(f\"⚠️ Missing EF file, skipping: {ef_file}\")\n",
    "                continue\n",
    "            try:\n",
    "                feats5 = _read_feature_from_ef(ef_file, n_atoms, aggregate=True)  # 5D\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Failed to read EF file, skipping: {ef_file}, error: {e}\")\n",
    "                continue\n",
    "\n",
    "            U_fit = float(feats5 @ alpha)\n",
    "\n",
    "            # Per-line output: name, real_U, fit_U, 5 features, 5 alpha parameters\n",
    "            f.write(\n",
    "                f\"{name} {real_U:.6f} {U_fit:.6f} \"\n",
    "                + \" \".join([f\"{v:.6f}\" for v in feats5.tolist()])\n",
    "                + \" \"\n",
    "                + \" \".join([f\"{a:.6f}\" for a in alpha.tolist()])\n",
    "                + \"\\n\"\n",
    "            )\n",
    "\n",
    "    print(f\"✅ All results written to: {output_combined_file}\")\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"/mnt/xyz_folder\"\n",
    "for amino in [\"ALA\"]:\n",
    "    fit_and_predict_U(work_dir, residue_name=amino, n_train=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
